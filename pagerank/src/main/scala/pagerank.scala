import org.apache.spark.{SparkConf, SparkContext}
import scala.collection.mutable.ArrayBuffer
import scala.collection.mutable.Set
import org.apache.spark.rdd.RDD

object SparkPageRank {
  //æž„å»ºè¾¹
  def readFromTxtByLine(sc: SparkContext, resultArray: scala.collection.mutable.ArrayBuffer[(String, String)], allLines: scala.collection.mutable.Set[String]) = {
    var textFile = sc.textFile("hdfs://master:9000/final/pagerank/resultURL.txt")
    val lines = textFile.collect().toList
    var foundLine: String = ""
    var saveNextLine = false

    lines.foreach { line =>
      if (saveNextLine) {
        foundLine = line  // å°†ä¸‹ä¸€è¡Œä¿å­˜åˆ° foundLine å˜é‡
        allLines += line
        saveNextLine = false
      }else if (line.contains("ðŸŽ")) {
        println(s"ç¬¦å·ðŸŽåœ¨è¯¥è¡Œä¸­å­˜åœ¨ï¼š$line")
        saveNextLine = true  // è®¾ç½®æ ‡è¯†ä»¥ä¿å­˜ä¸‹ä¸€è¡Œ
      } else {
        println(s"è¯¥è¡Œä¸­ä¸å­˜åœ¨ç¬¦å·ðŸŽï¼š$line")
        allLines += line
        resultArray += ((foundLine,line))
      }
    }
  }

  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setAppName("PageRank").setMaster("local[*]")
    val sc = new SparkContext(conf)
    val links1 = scala.collection.mutable.ArrayBuffer[(String, String)]()
    val allLines = scala.collection.mutable.Set[String]()

    readFromTxtByLine(sc,links1,allLines)
    
    val groupedLinks: RDD[(String, List[String])] = sc.parallelize(links1).groupBy(_._1).mapValues(_.map(_._2).toList)
    val allLinesRDD: RDD[String] = sc.parallelize(allLines.toSeq)

    val iters = 8
    var ranks: RDD[(String, Double)]= groupedLinks.mapValues(v => 1.0)
    // ranks.foreach(println)

    for(i<-1 to iters){
      val contribs = groupedLinks.join(ranks).values.flatMap{
        case (urls,rank)=>
        val size = urls.size
        urls.map(url=>(url, rank/size))
      }
      ranks=contribs.reduceByKey(_+_).mapValues(0.15+0.85*_) 
      val missingKeysRdd = allLinesRDD.subtract(ranks.keys)
      val defaultRanksRdd = missingKeysRdd.map(key => (key, 0.15))
      ranks = ranks.union(defaultRanksRdd)
    }
    // æ¯æ¬¡è¿­ä»£ç»“æŸåŽï¼Œå°† ranks å†™å…¥ result.txt
    ranks
    .coalesce(1)  // å°†ç»“æžœåˆå¹¶ä¸ºä¸€ä¸ªåˆ†åŒº
    .map { case (key, value) => s"$key,$value" }
    .saveAsTextFile("hdfs://master:9000/final/pagerank/result")
  }
}